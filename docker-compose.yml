version: '3.5'

services:  
  # redis:
  #   image: redis:latest
  #   healthcheck:
  #     test: [ "CMD-SHELL", "redis-cli ping | grep PONG" ]
  #     interval: 1s
  #     timeout: 3s
  #     retries: 5
  #   command: [ "redis-server" ]

  chromadb:
    image: chromadb/chroma:1.5.0
    volumes:
      - chromadb_volume:/chroma/chroma
    environment:
      - IS_PERSISTENT=TRUE
      - PERSIST_DIRECTORY=/chroma/chroma
      - ANONYMIZED_TELEMETRY=${ANONYMIZED_TELEMETRY:-TRUE}

  vllm:
    image: nvcr.io/nvidia/vllm:25.12.post1-py3
    container_name: vllm
    volumes:
      - /opt/hf-cache:/root/.cache/huggingface
    entrypoint: ["vllm", "serve", "--model", "acezxn/ACI_Cyber_Base_GPT_OSS_20B", "--gpu-memory-utilization", "0.5"]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  aci-ai-backend:
    build:
      context: .
      dockerfile: docker/backend/Dockerfile
    ports:
      - 8001:8000
    volumes:
      - model_volume:/app/models
      - db_volume:/app/database
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [ gpu ]
    depends_on:
      - chromadb
      - vllm

volumes:
  chromadb_volume:
  db_volume:
  model_volume:
